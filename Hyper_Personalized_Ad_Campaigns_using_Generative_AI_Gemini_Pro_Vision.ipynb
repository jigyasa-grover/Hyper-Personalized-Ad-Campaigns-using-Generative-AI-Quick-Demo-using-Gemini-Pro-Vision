{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyPhuF89/TsSK2dzK4IHkwcQ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jigyasa-grover/Hyper-Personalized-Ad-Campaigns-using-Generative-AI-Quick-Demo-using-Gemini-Pro-Vision/blob/main/Hyper_Personalized_Ad_Campaigns_using_Generative_AI_Gemini_Pro_Vision.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Hyperpersonalized Ad Campaigns using Generative AI: Gemini Pro Vision"
      ],
      "metadata": {
        "id": "lw8xPb1W9Ouw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setup"
      ],
      "metadata": {
        "id": "ersb6iCk92o9"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "ulVTG1mKEOpX"
      },
      "outputs": [],
      "source": [
        "!pip install -q google-generativeai==0.3.1\n",
        "!pip install -q gradio"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import google.generativeai as genai\n",
        "from google.colab import userdata\n",
        "\n",
        "from pathlib import Path\n",
        "import gradio as gr\n",
        "\n",
        "print(genai.__version__)\n",
        "genai.configure(api_key = userdata.get('GEMINI_KEY'))"
      ],
      "metadata": {
        "id": "pxgBW7mgMwYG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1dcf3d2e-6473-433a-a8b3-49f5cc3daba8"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.3.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Generative AI Model Configuration"
      ],
      "metadata": {
        "id": "BWIUd2l6GnO-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "GENERATION_CONFIG = {\n",
        "  \"temperature\": 0.4,\n",
        "  \"top_p\": 1,\n",
        "  \"top_k\": 32,\n",
        "  \"max_output_tokens\": 4096,\n",
        "}\n",
        "\n",
        "SAFETY_SETTINGS = [\n",
        "  {\n",
        "    \"category\": \"HARM_CATEGORY_HARASSMENT\",\n",
        "    \"threshold\": \"BLOCK_MEDIUM_AND_ABOVE\"\n",
        "  },\n",
        "  {\n",
        "    \"category\": \"HARM_CATEGORY_HATE_SPEECH\",\n",
        "    \"threshold\": \"BLOCK_MEDIUM_AND_ABOVE\"\n",
        "  },\n",
        "  {\n",
        "    \"category\": \"HARM_CATEGORY_SEXUALLY_EXPLICIT\",\n",
        "    \"threshold\": \"BLOCK_MEDIUM_AND_ABOVE\"\n",
        "  },\n",
        "  {\n",
        "    \"category\": \"HARM_CATEGORY_DANGEROUS_CONTENT\",\n",
        "    \"threshold\": \"BLOCK_MEDIUM_AND_ABOVE\"\n",
        "  }\n",
        "]"
      ],
      "metadata": {
        "id": "g2Gkr9kSSh-t"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Generative AI Model Instance"
      ],
      "metadata": {
        "id": "2dE4Bs6O_TdR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "GENERATIVE_AI_MODEL = genai.GenerativeModel(\n",
        "    model_name = \"gemini-pro-vision\",\n",
        "    generation_config = GENERATION_CONFIG,\n",
        "    safety_settings = SAFETY_SETTINGS\n",
        ")"
      ],
      "metadata": {
        "id": "skHrcsEwSt7S"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Inut Prompt"
      ],
      "metadata": {
        "id": "D5YL5sB1H7LL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "NUM_USER_PERSONAS = 4\n",
        "\n",
        "BASE_INPUT_PROMPT = \"\"\"\n",
        "  We want to run hyper-personalized online ad campaigns for the product in the picture above.\n",
        "  Create ad campaign strategies that target the following four user personas.\n",
        "  Each strategy should include suggestions for compelling ad copy that would appeal strongly to the specific persona.\n",
        "  Tailor the ad campaigns to address the specific needs, interests, and pain points of each persona.\n",
        "  Consider using dynamic ad elements, product details and real-time data for even more granular personalization.\n",
        "  Please include a quirky personalized hashtag in the ad campaign text. The ad campaign text should not be more than 150 words.\n",
        "\"\"\"\n",
        "# + user_persona_prompt (parsed using the parse_persona_string(..) helper fn)"
      ],
      "metadata": {
        "id": "SDw7Sm6cSxz4"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Helper Functions"
      ],
      "metadata": {
        "id": "YtQ6mf-__d51"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def process_input_image(file_location):\n",
        "    if not (img := Path(file_location)).exists():\n",
        "        raise FileNotFoundError(f\"Could not find image: {img}\")\n",
        "    image = [{\n",
        "          \"mime_type\": \"image/jpeg\",\n",
        "          \"data\": Path(file_location).read_bytes()\n",
        "      }]\n",
        "    return image"
      ],
      "metadata": {
        "id": "45Vqjm6IBknI"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def render_input_image(input_files):\n",
        "    input_files_paths = [file.name for file in input_files]\n",
        "    return input_files_paths[0]"
      ],
      "metadata": {
        "id": "a-GjZP1uIJuS"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def parse_persona_string(user_persona_instance, user_persona_string):\n",
        "    user_persona = user_persona_string.split(\",\")\n",
        "    parsed_user_persona = \"\\n\\t\".join([\n",
        "        f\"{key.capitalize()}: {value}\" for key, value in zip(\n",
        "              [\"Age\", \"Gender\", \"Location\", \"Occupation\"], user_persona\n",
        "            )\n",
        "        ])\n",
        "    return f\"\\nUser Persona {user_persona_instance}:\\n\\t{parsed_user_persona}\""
      ],
      "metadata": {
        "id": "tXh3XlfcV3KK"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_genAI_model_response(input_prompt, user_personas, input_image_location):\n",
        "    image_prompt = process_input_image(input_image_location)\n",
        "    user_personas_prompt = \"\"\n",
        "    for i in range(NUM_USER_PERSONAS):\n",
        "      user_personas_prompt += parse_persona_string(i+1, user_personas[i])\n",
        "    prompt_parts = [input_prompt + user_personas_prompt, image_prompt[0]]\n",
        "    response = GENERATIVE_AI_MODEL.generate_content(prompt_parts)\n",
        "    return response.text"
      ],
      "metadata": {
        "id": "I-f3KG_9Swdf"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def output_image_and_genAI_model_response(files, *user_personas):\n",
        "    file_paths = [file.name for file in files]\n",
        "    if file_paths:\n",
        "        response = generate_genAI_model_response(BASE_INPUT_PROMPT, user_personas, file_paths[0])\n",
        "    return file_paths[0], response"
      ],
      "metadata": {
        "id": "oT-vpLzaIatf"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with gr.Blocks() as demo:\n",
        "    header = gr.Markdown(\n",
        "        \"\"\"\n",
        "          # Hyperpersonalized Ad Campaigns using Generative AI: Gemini Pro Vision\n",
        "        \"\"\")\n",
        "    user_personas_textboxes = [\n",
        "        gr.Textbox(label=\"User Persona #\" + str(i+1), placeholder = \"age, gender, location, profession\")\n",
        "        for i in range(NUM_USER_PERSONAS)\n",
        "    ]\n",
        "    image_upload_button = gr.UploadButton(\"Click to upload an image of the product to be advertised.\", file_types=[\"image\"], file_count=\"multiple\")\n",
        "\n",
        "    input = [image_upload_button]\n",
        "    for i in range(NUM_USER_PERSONAS):\n",
        "      input.append(user_personas_textboxes[i])\n",
        "\n",
        "    image_output = gr.Image()\n",
        "\n",
        "    generate_button = gr.Button(value=\"Generate!\")\n",
        "\n",
        "    genAI_model_response = gr.Markdown()\n",
        "    output = [image_output, genAI_model_response]\n",
        "\n",
        "    image_upload_button.upload(render_input_image, image_upload_button, image_output)\n",
        "    generate_button.click(output_image_and_genAI_model_response, input, output)\n",
        "\n",
        "demo.launch(debug=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 648
        },
        "id": "ZePQJK3vSy92",
        "outputId": "b4d50998-854f-454c-9579-a077ced0857a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Setting queue=True in a Colab notebook requires sharing enabled. Setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n",
            "Running on public URL: https://3bb74fac25923349bd.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://3bb74fac25923349bd.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}